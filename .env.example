# Vulna Configuration
# Copy this file to .env and customize as needed

# LLM Configuration
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
OLLAMA_MODEL=qwen2.5-coder:14b
LLM_WORKERS=3

# Alternative Models (uncomment to use):
# OLLAMA_MODEL=deepseek-r1:14b           # Reasoning-focused, excellent for security
# OLLAMA_MODEL=qwen2.5-coder:latest      # Lighter version (7B)  
# OLLAMA_MODEL=llama3-groq-tool-use:8b   # Tool-use specialized
# OLLAMA_MODEL=llama3.2:latest           # Lightweight but limited (2B)

# Proxy Configuration
PROXY_HOST=localhost
PROXY_PORT=8080

# Dashboard Configuration  
DASHBOARD_HOST=localhost
DASHBOARD_PORT=3000

# File Paths
REQUESTS_FILE=data/requests.jsonl
FINDINGS_FILE=data/findings.jsonl

# Performance Settings
QUEUE_MAX_SIZE=1000
REQUEST_TIMEOUT=30
ANALYSIS_TIMEOUT=60

# Security Settings
CERTIFICATE_VALIDATION=false
SSL_VERIFICATION=false
